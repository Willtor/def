/* Copyright (C) 2018  DEF Authors

   Permission is hereby granted, free of charge, to any person obtaining a
   copy of this software and associated documentation files (the "Software"),
   to deal in the Software without restriction, including without limitation
   the rights to use, copy, modify, merge, publish, distribute, sublicense,
   and/or sell copies of the Software, and to permit persons to whom the
   Software is furnished to do so, subject to the following conditions:

   The above copyright notice and this permission notice shall be included in
   all copies or substantial portions of the Software.

   THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
   IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
   FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
   THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
   LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
   FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
   DEALINGS IN THE SOFTWARE.
 */

/* RH NOrec: adapted from the pseudocode provided in:
   Alex Matveev, Nir Shavit.  Reduced Hardware NOrec: A Safe and Scalable
   Hybrid Transactional Memory.  ASPLOS, 2015.
 */

typedef __rhnorec_ctx =
    { jump_buffer [20]*void,
      is_tx_version u64,
      max_reads i16,
      expected_length i16,
      prefix_reads i16,
      is_rh_prefix_active bool,
      is_rh_active bool,
      is_write_detected bool,
      is_readonly bool
    };

typedef g_state_t =
    { htm_lock          volatile i64,
      buff_1            [56]char,
      clock             volatile u64,
      buff_2            [56]char,
      num_of_fallbacks  volatile u64
    };

global g_state g_state_t;

/**************************************************************************/
/*                               Fast path                                */
/**************************************************************************/

export
def __rhnorec_fast_path_start () -> bool
begin
    var n_retries = 4;
retry:
    while g_state.htm_lock != 0 do
        // busy-wait until the lock is free.
    od

    if -1 != __builtin_xbegin() then
        // HTM failed.
        if n_retries <= 0 then
            // Fallback to slow path.
            return false;
        fi
        --n_retries;
        goto retry;
    fi

    // HTM started.
    if g_state.htm_lock != 0 then
        // Get the lock into the read-set.
        __builtin_xabort(0);
    fi
    return true;
end

export
def __rhnorec_fast_path_commit (ctx *__rhnorec_ctx) -> void
begin
    if ctx.is_readonly then
        // Statically detected by the compiler.
        __builtin_xend();
        return;
    fi

    if g_state.num_of_fallbacks > 0 then
        if is_locked(g_state.clock) then
            __builtin_xabort(0);
        fi
        ++g_state.clock;
    fi

    __builtin_xend();
end

/**************************************************************************/
/*                               Slow path                                */
/**************************************************************************/

export
def __rhnorec_slow_path_start (ctx *__rhnorec_ctx) -> void
begin
    if htm_prefix_start(ctx) then
        return;
    fi

    // Algorithm 2.
    // FIXME: Wrap incr g_num_fallbacks.
    g_state.num_of_fallbacks atomic += 1;
    ctx.is_write_detected = false;
    do
        // Save the clock.
        ctx.is_tx_version = g_state.clock;
    od while is_locked(ctx.is_tx_version);
end

def htm_prefix_start (ctx *__rhnorec_ctx) -> bool
begin
    var n_retries = 4;
retry:
    while g_state.htm_lock != 0 do
        // busy-wait until the lock is free.
    od

    if -1 != __builtin_xbegin() then
        if n_retries <= 0 then
            return false;
        fi
        --n_retries;
        goto retry;
    fi

    ctx.is_rh_prefix_active = true;
    if g_state.htm_lock != 0 then
        __builtin_xabort(0);
    fi
    ctx.max_reads = ctx.expected_length;
    ctx.prefix_reads = 0;
    return true;
end

export
def __rhnorec_slow_path_read_64 (ctx *__rhnorec_ctx, addr *u64) -> u64
begin
    if ctx.is_rh_prefix_active then
        ++ctx.prefix_reads;
        if ctx.prefix_reads < ctx.max_reads then
            return addr[0];
        fi
        commit_rh_htm_prefix(ctx);
    fi

    // Algorithm 2.
    var ret = addr[0];
    if ctx.is_tx_version != g_state.clock then
        restart(ctx);
    fi
    return ret;
end

export
def __rhnorec_slow_path_write_64 (ctx *__rhnorec_ctx, addr *u64, value u64)
        -> void
begin
    if ctx.is_rh_prefix_active then
        commit_rh_htm_prefix(ctx);
    fi

    // Algorithm 2.
    if !ctx.is_write_detected then
        handle_first_write(ctx);
    fi
    addr[0] = value;
end

def commit_rh_htm_prefix (ctx *__rhnorec_ctx) -> void
begin
    g_state.num_of_fallbacks atomic += 1;
    ctx.is_write_detected = false;
    ctx.is_tx_version = g_state.clock;
    if is_locked(ctx.is_tx_version) then
        __builtin_xabort(0);
    fi
    __builtin_xend();
    ctx.is_rh_prefix_active = false;
end

def handle_first_write (ctx *__rhnorec_ctx) -> void
begin
    ctx.is_write_detected = true;
    acquire_clock_lock(ctx);
    if !start_htm_postfix(ctx) then
        g_state.htm_lock = 1;
    fi
end

def start_htm_postfix (ctx *__rhnorec_ctx) -> bool
begin
    var n_retries = 4;
retry:
    if -1 != __builtin_xbegin() then
        if n_retries <= 0 then
            return false;
        fi
        --n_retries;
        goto retry;
    fi
    ctx.is_rh_active = true;
    return true;
end

def acquire_clock_lock (ctx *__rhnorec_ctx) -> bool
begin
    var marked = set_lock_bit(ctx.is_tx_version);
    if !__builtin_cas(&g_state.clock, ctx.is_tx_version, marked) then
        // FIXME: What's the deal with restart?  And why does this function
        // never return false?
        restart(ctx);
    fi
    ctx.is_tx_version = marked;
    return true;
end

export
def __rhnorec_mixed_slow_path_commit (ctx *__rhnorec_ctx) -> void
begin
    if ctx.is_rh_prefix_active then
        __builtin_xend();
        return;
    fi

    // Algorithm 2.
    if !ctx.is_write_detected then
        // Read-only transaction.
        g_state.num_of_fallbacks atomic -= 1;
    fi

    // If RH is on, then commit.
    if ctx.is_rh_active then
        __builtin_xend();
        ctx.is_rh_active = false;
    fi

    // If HTM lock is taken, then release it.
    if g_state.htm_lock != 0 then
        g_state.htm_lock = 0;
    fi

    // Update the clock: clear lock bit and increment.
    g_state.clock = clear_lock_bit(g_state.clock) + 1; // FIXME: atomic?
    g_state.num_of_fallbacks atomic -= 1;
end

/**************************************************************************/
/*                               Utilities                                */
/**************************************************************************/

def restart (ctx *__rhnorec_ctx) -> void
begin
    // FIXME: Do I need to zero-out the non-jump_buffer portion of ctx?
    __builtin_longjmp(ctx.jump_buffer, 1);
end

def is_locked (clock u64) -> bool =
    (0x8000000000000000U64 & clock) != 0U64;

def set_lock_bit (clock u64) -> u64 =
    0x8000000000000000U64 | clock;

def clear_lock_bit (clock u64) -> u64 =
    0x7FFFFFFFFFFFFFFFU64 & clock;
